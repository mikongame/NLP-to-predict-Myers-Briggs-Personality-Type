{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://bit.ly/2VnXWr2\" width=\"100\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final project: NLP to predict Myers-Briggs Personality Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:43.831594Z",
     "start_time": "2020-05-30T19:33:39.179326Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras.metrics\n",
    "from keras import regularizers, initializers, optimizers, callbacks\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.utils import class_weight\n",
    "from keras.layers import *\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T18:09:27.528161Z",
     "start_time": "2020-05-29T18:09:27.525169Z"
    }
   },
   "source": [
    "## 4. Model building and evaluation: Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:44.613541Z",
     "start_time": "2020-05-30T19:33:43.833589Z"
    }
   },
   "outputs": [],
   "source": [
    "spacy_nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:44.619488Z",
     "start_time": "2020-05-30T19:33:44.615499Z"
    }
   },
   "outputs": [],
   "source": [
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:44.695284Z",
     "start_time": "2020-05-30T19:33:44.622480Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 100000    # max no. of words for tokenizer\n",
    "MAX_SEQUENCE_LENGTH = 200 # max length of each entry (sentence), including padding\n",
    "VALIDATION_SPLIT = 0.2   # data for validation (not used in training)\n",
    "EMBEDDING_DIM = 100      # embedding dimensions for word vectors (word2vec/GloVe)\n",
    "GLOVE_DIR = \"glove_data/glove.6B/glove.6B.\"+str(EMBEDDING_DIM)+\"d.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:44.947614Z",
     "start_time": "2020-05-30T19:33:44.696282Z"
    }
   },
   "outputs": [],
   "source": [
    "mbti_df_clean = pd.read_pickle(\"data/output_pickles/mbti_clean_text.pkl\")\n",
    "result_umap_types  = pd.read_csv(\"data/output_csv/result_umap_types.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:44.965568Z",
     "start_time": "2020-05-30T19:33:44.949609Z"
    }
   },
   "outputs": [],
   "source": [
    "mbti_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:45.062307Z",
     "start_time": "2020-05-30T19:33:44.967562Z"
    }
   },
   "outputs": [],
   "source": [
    "result_umap_types.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:45.184888Z",
     "start_time": "2020-05-30T19:33:45.065300Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(result_umap_types[\"enfj\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    enfj: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"enfp\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    enfp: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"entj\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    entj: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"entp\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    entp: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"esfj\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    esfj: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"esfp\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    esfp: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"estj\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    estj: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"estp\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    estp: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"infj\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    infj: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"infp\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    infp: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"intj\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    intj: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"intp\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    intp: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"isfj\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    isfj: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"isfp\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    isfp: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"istj\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    istj: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"istp\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    istp: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:45.261216Z",
     "start_time": "2020-05-30T19:33:45.187880Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "labels_dict = {0: 190 , 1: 675, 2: 231, 3: 685, 4: 42, 5: 48, 6: 39, 7: 89, 8: 1470,\n",
    "                9: 1832, 10: 1091, 11: 1304, 12: 166, 13: 271, 14: 205, 15: 337}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:45.355526Z",
     "start_time": "2020-05-30T19:33:45.263160Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_class_weight(labels_dict):\n",
    "    total = 8675\n",
    "    keys = labels_dict.keys()\n",
    "    class_weight = dict()\n",
    "\n",
    "    for key in keys:\n",
    "        score = math.log(total/float(labels_dict[key]))\n",
    "        class_weight[key] = score if score > 1.0 else 1.0\n",
    "\n",
    "    return class_weight\n",
    "\n",
    "class_weights = create_class_weight(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:45.468723Z",
     "start_time": "2020-05-30T19:33:45.357487Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "labels = [\"enfj\", \"enfp\", \"entj\", \"entp\", \"esfj\", \"esfp\", \"estj\", \"estp\", \"infj\", \"infp\", \"intj\", \"intp\", \"isfj\", \n",
    "          \"isfp\", \"istj\", \"istp\"]\n",
    "y = result_umap_types[labels].values\n",
    "X = mbti_df_clean[\"posts_clean\"]\n",
    "#extra = mbti_df_clean[\"word_per_comment\",\"variance_of_word_counts\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:45.588601Z",
     "start_time": "2020-05-30T19:33:45.470718Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "print ((X_train.shape),(y_train.shape),(X_test.shape),(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:45.672516Z",
     "start_time": "2020-05-30T19:33:45.590594Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = list(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:45.766903Z",
     "start_time": "2020-05-30T19:33:45.674510Z"
    }
   },
   "outputs": [],
   "source": [
    "texts = [line for line in X_train] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:48.242149Z",
     "start_time": "2020-05-30T19:33:45.767930Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:49.783751Z",
     "start_time": "2020-05-30T19:33:48.242860Z"
    }
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "print('Vocabulary size:', len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:49.917419Z",
     "start_time": "2020-05-30T19:33:49.785738Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pad_sequences(sequences, padding = 'post', maxlen = MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:50.763161Z",
     "start_time": "2020-05-30T19:33:49.919408Z"
    }
   },
   "outputs": [],
   "source": [
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = y_train[indices]\n",
    "#Aplicar a variables extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:50.894353Z",
     "start_time": "2020-05-30T19:33:50.765012Z"
    }
   },
   "outputs": [],
   "source": [
    "num_validation_samples = int(VALIDATION_SPLIT*data.shape[0])\n",
    "x_train = data[: -num_validation_samples]\n",
    "y_train = labels[: -num_validation_samples]\n",
    "x_val = data[-num_validation_samples: ]\n",
    "y_val = labels[-num_validation_samples: ]\n",
    "\n",
    "print ((x_train.shape),(y_train.shape),(x_val.shape),(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:50.982325Z",
     "start_time": "2020-05-30T19:33:50.896325Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of entries in each category:')\n",
    "print('training: ', y_train.sum(axis=0))\n",
    "print('validation: ', y_val.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:51.116812Z",
     "start_time": "2020-05-30T19:33:50.984306Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Tokenized sentences: \\n', data[10])\n",
    "print('One hot label: \\n', labels[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:34:05.738483Z",
     "start_time": "2020-05-30T19:33:51.118780Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open(GLOVE_DIR, encoding=\"UTF-8\")\n",
    "print('Loading GloVe from:', GLOVE_DIR,'...', end='')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    embeddings_index[word] = np.asarray(values[1:], dtype='float32')\n",
    "f.close()\n",
    "print(\"Done.\\n Proceeding with Embedding Matrix...\", end=\"\")\n",
    "\n",
    "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print(\" Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:34:05.905005Z",
     "start_time": "2020-05-30T19:34:05.743464Z"
    }
   },
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                           EMBEDDING_DIM,\n",
    "                           weights = [embedding_matrix],\n",
    "                           input_length = MAX_SEQUENCE_LENGTH,\n",
    "                           trainable=False,\n",
    "                           name = 'embeddings')\n",
    "embedded_sequences = embedding_layer(sequence_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:39:13.960997Z",
     "start_time": "2020-05-30T19:39:13.791451Z"
    }
   },
   "outputs": [],
   "source": [
    "x = LSTM(60, return_sequences=True,name='lstm_layer')(embedded_sequences)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "# hacer merge y añadir extras\n",
    "preds = Dense(16, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:34:07.170835Z",
     "start_time": "2020-05-30T19:34:07.041133Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.02)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer=opt,\n",
    "             weighted_metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:34:07.341332Z",
     "start_time": "2020-05-30T19:34:07.172782Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:42.581405Z",
     "start_time": "2020-05-30T19:34:07.342329Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Training progress:')\n",
    "history = model.fit(x_train, y_train, epochs = 20, batch_size=64, validation_data=(x_val, y_val), verbose=2, \n",
    "                    class_weight=class_weights)\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:42.591375Z",
     "start_time": "2020-05-30T19:37:42.582399Z"
    }
   },
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history) \n",
    "\n",
    "hist_df.to_csv(\"data/output_csv/types_hist_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:43.555440Z",
     "start_time": "2020-05-30T19:37:42.593369Z"
    }
   },
   "outputs": [],
   "source": [
    "types_hist_df = pd.read_csv(\"data/output_csv/types_hist_df.csv\")\n",
    "types_hist_df.drop([\"Unnamed: 0\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:43.698606Z",
     "start_time": "2020-05-30T19:37:43.557402Z"
    }
   },
   "outputs": [],
   "source": [
    "types_hist_df['val_f1'] = ((types_hist_df[\"val_precision_1\"]*types_hist_df[\"val_recall_1\"])/\n",
    "                           (types_hist_df[\"val_precision_1\"]+types_hist_df[\"val_recall_1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:43.791324Z",
     "start_time": "2020-05-30T19:37:43.700567Z"
    }
   },
   "outputs": [],
   "source": [
    "types_hist_df = types_hist_df[['val_loss', 'loss', 'val_accuracy', 'accuracy', 'val_precision_1', 'precision_1',\n",
    "                  'val_recall_1', 'recall_1', 'val_f1']]\n",
    "types_hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:44.292982Z",
     "start_time": "2020-05-30T19:37:43.793319Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "plt.plot(types_hist_df[['val_loss', 'val_accuracy', 'val_precision_1', 'val_recall_1', 'val_f1']])\n",
    "plt.plot (types_hist_df[['loss', 'accuracy', 'precision_1', 'recall_1']], '--')\n",
    "\n",
    "plt.title('Training and Validation: Types')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Metrics')\n",
    "plt.legend(['val_loss', 'val_accuracy', 'val_precision_1', 'val_recall_1', 'val_f1', \n",
    "            'loss', 'accuracy', 'precision_1', 'recall_1'])\n",
    "plt.savefig(\"images/output_images/types_history.png\")\n",
    "\n",
    "sns.set_context(\"talk\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**comments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:44.947614Z",
     "start_time": "2020-05-30T19:33:44.696282Z"
    }
   },
   "outputs": [],
   "source": [
    "mbti_df_clean = pd.read_pickle(\"data/output_pickles/mbti_clean_text.pkl\")\n",
    "result_umap_types  = pd.read_csv(\"data/output_csv/result_umap_types.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:44.965568Z",
     "start_time": "2020-05-30T19:33:44.949609Z"
    }
   },
   "outputs": [],
   "source": [
    "mbti_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:45.062307Z",
     "start_time": "2020-05-30T19:33:44.967562Z"
    }
   },
   "outputs": [],
   "source": [
    "result_umap_types.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:45.184888Z",
     "start_time": "2020-05-30T19:33:45.065300Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(result_umap_types[\"enfj\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    enfj: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"enfp\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    enfp: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"entj\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    entj: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"entp\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    entp: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"esfj\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    esfj: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"esfp\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    esfp: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"estj\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    estj: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"estp\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    estp: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"infj\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    infj: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"infp\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    infp: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"intj\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    intj: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"intp\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    intp: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"isfj\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    isfj: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"isfp\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    isfp: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"istj\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    istj: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_types[\"istp\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    istp: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:45.261216Z",
     "start_time": "2020-05-30T19:33:45.187880Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "labels_dict = {0: 190 , 1: 675, 2: 231, 3: 685, 4: 42, 5: 48, 6: 39, 7: 89, 8: 1470,\n",
    "                9: 1832, 10: 1091, 11: 1304, 12: 166, 13: 271, 14: 205, 15: 337}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:45.355526Z",
     "start_time": "2020-05-30T19:33:45.263160Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_class_weight(labels_dict):\n",
    "    total = 8675\n",
    "    keys = labels_dict.keys()\n",
    "    class_weight = dict()\n",
    "\n",
    "    for key in keys:\n",
    "        score = math.log(total/float(labels_dict[key]))\n",
    "        class_weight[key] = score if score > 1.0 else 1.0\n",
    "\n",
    "    return class_weight\n",
    "\n",
    "class_weights = create_class_weight(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:45.468723Z",
     "start_time": "2020-05-30T19:33:45.357487Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "labels = [\"enfj\", \"enfp\", \"entj\", \"entp\", \"esfj\", \"esfp\", \"estj\", \"estp\", \"infj\", \"infp\", \"intj\", \"intp\", \"isfj\", \n",
    "          \"isfp\", \"istj\", \"istp\"]\n",
    "y = result_umap_types[labels].values\n",
    "X = mbti_df_clean[\"posts_clean\"]\n",
    "#extra = mbti_df_clean[\"word_per_comment\",\"variance_of_word_counts\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:45.588601Z",
     "start_time": "2020-05-30T19:33:45.470718Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "print ((X_train.shape),(y_train.shape),(X_test.shape),(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:45.672516Z",
     "start_time": "2020-05-30T19:33:45.590594Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = list(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:45.766903Z",
     "start_time": "2020-05-30T19:33:45.674510Z"
    }
   },
   "outputs": [],
   "source": [
    "texts = [line for line in X_train] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:48.242149Z",
     "start_time": "2020-05-30T19:33:45.767930Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:49.783751Z",
     "start_time": "2020-05-30T19:33:48.242860Z"
    }
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "print('Vocabulary size:', len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:49.917419Z",
     "start_time": "2020-05-30T19:33:49.785738Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pad_sequences(sequences, padding = 'post', maxlen = MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:50.763161Z",
     "start_time": "2020-05-30T19:33:49.919408Z"
    }
   },
   "outputs": [],
   "source": [
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = y_train[indices]\n",
    "#Aplicar a variables extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:50.894353Z",
     "start_time": "2020-05-30T19:33:50.765012Z"
    }
   },
   "outputs": [],
   "source": [
    "num_validation_samples = int(VALIDATION_SPLIT*data.shape[0])\n",
    "x_train = data[: -num_validation_samples]\n",
    "y_train = labels[: -num_validation_samples]\n",
    "x_val = data[-num_validation_samples: ]\n",
    "y_val = labels[-num_validation_samples: ]\n",
    "\n",
    "print ((x_train.shape),(y_train.shape),(x_val.shape),(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:50.982325Z",
     "start_time": "2020-05-30T19:33:50.896325Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of entries in each category:')\n",
    "print('training: ', y_train.sum(axis=0))\n",
    "print('validation: ', y_val.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:33:51.116812Z",
     "start_time": "2020-05-30T19:33:50.984306Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Tokenized sentences: \\n', data[10])\n",
    "print('One hot label: \\n', labels[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:34:05.738483Z",
     "start_time": "2020-05-30T19:33:51.118780Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open(GLOVE_DIR, encoding=\"UTF-8\")\n",
    "print('Loading GloVe from:', GLOVE_DIR,'...', end='')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    embeddings_index[word] = np.asarray(values[1:], dtype='float32')\n",
    "f.close()\n",
    "print(\"Done.\\n Proceeding with Embedding Matrix...\", end=\"\")\n",
    "\n",
    "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print(\" Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:34:05.905005Z",
     "start_time": "2020-05-30T19:34:05.743464Z"
    }
   },
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                           EMBEDDING_DIM,\n",
    "                           weights = [embedding_matrix],\n",
    "                           input_length = MAX_SEQUENCE_LENGTH,\n",
    "                           trainable=False,\n",
    "                           name = 'embeddings')\n",
    "embedded_sequences = embedding_layer(sequence_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:39:13.960997Z",
     "start_time": "2020-05-30T19:39:13.791451Z"
    }
   },
   "outputs": [],
   "source": [
    "x = LSTM(60, return_sequences=True,name='lstm_layer')(embedded_sequences)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "# hacer merge y añadir extras\n",
    "preds = Dense(16, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:44.429617Z",
     "start_time": "2020-05-30T19:37:44.293979Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.005)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer=opt,\n",
    "             weighted_metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:44.602973Z",
     "start_time": "2020-05-30T19:37:44.431611Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:39:27.720932Z",
     "start_time": "2020-05-30T19:39:27.689985Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Training progress:')\n",
    "history = model.fit(x_train, y_train, epochs = 20, batch_size=64, validation_data=(x_val, y_val), verbose=2, \n",
    "                    class_weight=class_weights)\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.117597Z",
     "start_time": "2020-05-30T19:33:39.271Z"
    }
   },
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history) \n",
    "\n",
    "hist_df.to_csv(\"data/output_csv/types_hist_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.118594Z",
     "start_time": "2020-05-30T19:33:39.274Z"
    }
   },
   "outputs": [],
   "source": [
    "types_hist_df = pd.read_csv(\"data/output_csv/types_hist_df.csv\")\n",
    "types_hist_df.drop([\"Unnamed: 0\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.120591Z",
     "start_time": "2020-05-30T19:33:39.277Z"
    }
   },
   "outputs": [],
   "source": [
    "types_hist_df['val_f1'] = ((types_hist_df[\"val_precision_1\"]*types_hist_df[\"val_recall_1\"])/\n",
    "                           (types_hist_df[\"val_precision_1\"]+types_hist_df[\"val_recall_1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.121602Z",
     "start_time": "2020-05-30T19:33:39.279Z"
    }
   },
   "outputs": [],
   "source": [
    "types_hist_df = types_hist_df[['val_loss', 'loss', 'val_accuracy', 'accuracy', 'val_precision_1', 'precision_1',\n",
    "                  'val_recall_1', 'recall_1', 'val_f1']]\n",
    "types_hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.122584Z",
     "start_time": "2020-05-30T19:33:39.281Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "plt.plot(types_hist_df[['val_loss', 'val_accuracy', 'val_precision_1', 'val_recall_1', 'val_f1']])\n",
    "plt.plot (types_hist_df[['loss', 'accuracy', 'precision_1', 'recall_1']], '--')\n",
    "\n",
    "plt.title('Training and Validation: Types')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Metrics')\n",
    "plt.legend(['val_loss', 'val_accuracy', 'val_precision_1', 'val_recall_1', 'val_f1', \n",
    "            'loss', 'accuracy', 'precision_1', 'recall_1'])\n",
    "plt.savefig(\"images/output_images/types_history.png\")\n",
    "\n",
    "sns.set_context(\"talk\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.nicepng.com/png/detail/148-1486992_discover-the-most-powerful-ways-to-automate-your.png\" width=\"1000\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.123581Z",
     "start_time": "2020-05-30T19:33:39.285Z"
    }
   },
   "outputs": [],
   "source": [
    "#raise SystemExit(\"Here it comes another quite consuming memory process. You should better not start it till everything else has itereated propperly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.125577Z",
     "start_time": "2020-05-30T19:33:39.287Z"
    }
   },
   "outputs": [],
   "source": [
    "mbti_df_clean = pd.read_pickle(\"data/output_pickles/mbti_clean_text.pkl\")\n",
    "result_umap_dimensions  = pd.read_csv(\"data/output_csv/result_umap_dimensions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.126587Z",
     "start_time": "2020-05-30T19:33:39.289Z"
    }
   },
   "outputs": [],
   "source": [
    "mbti_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.127571Z",
     "start_time": "2020-05-30T19:33:39.291Z"
    }
   },
   "outputs": [],
   "source": [
    "result_umap_dimensions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.129566Z",
     "start_time": "2020-05-30T19:33:39.294Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(result_umap_dimensions[\"i-e\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    i-e: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_dimensions[\"n-s\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    n-s: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_dimensions[\"t-f\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    t-f: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_dimensions[\"j-p\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    j-p: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.130563Z",
     "start_time": "2020-05-30T19:33:39.296Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "labels_dict = {0: 1999 , 1: 1997, 2: 4694, 3: 5241}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.131560Z",
     "start_time": "2020-05-30T19:33:39.299Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_class_weight(labels_dict):\n",
    "    total = 8675\n",
    "    keys = labels_dict.keys()\n",
    "    class_weight = dict()\n",
    "\n",
    "    for key in keys:\n",
    "        score = math.log(total/float(labels_dict[key]))\n",
    "        class_weight[key] = score if score > 1.0 else 1.0\n",
    "\n",
    "    return class_weight\n",
    "\n",
    "class_weights = create_class_weight(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.132569Z",
     "start_time": "2020-05-30T19:33:39.301Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = [\"i-e\", \"n-s\", \"t-f\", \"j-p\"]\n",
    "y = result_umap_dimensions[labels].values\n",
    "X = mbti_df_clean[\"posts_clean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.133556Z",
     "start_time": "2020-05-30T19:33:39.304Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "print ((X_train.shape),(y_train.shape),(X_test.shape),(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.134553Z",
     "start_time": "2020-05-30T19:33:39.307Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = list(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.135550Z",
     "start_time": "2020-05-30T19:33:39.309Z"
    }
   },
   "outputs": [],
   "source": [
    "texts = [line for line in X_train] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.136547Z",
     "start_time": "2020-05-30T19:33:39.311Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.138543Z",
     "start_time": "2020-05-30T19:33:39.314Z"
    }
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "print('Vocabulary size:', len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.140541Z",
     "start_time": "2020-05-30T19:33:39.316Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pad_sequences(sequences, padding = 'post', maxlen = MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.141551Z",
     "start_time": "2020-05-30T19:33:39.318Z"
    }
   },
   "outputs": [],
   "source": [
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = y_train[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.142531Z",
     "start_time": "2020-05-30T19:33:39.320Z"
    }
   },
   "outputs": [],
   "source": [
    "num_validation_samples = int(VALIDATION_SPLIT*data.shape[0])\n",
    "x_train = data[: -num_validation_samples]\n",
    "y_train = labels[: -num_validation_samples]\n",
    "x_val = data[-num_validation_samples: ]\n",
    "y_val = labels[-num_validation_samples: ]\n",
    "\n",
    "print ((x_train.shape),(y_train.shape),(x_val.shape),(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.143528Z",
     "start_time": "2020-05-30T19:33:39.323Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of entries in each category:')\n",
    "print('training: ', y_train.sum(axis=0))\n",
    "print('validation: ', y_val.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.145523Z",
     "start_time": "2020-05-30T19:33:39.325Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Tokenized sentences: \\n', data[10])\n",
    "print('One hot label: \\n', labels[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.146520Z",
     "start_time": "2020-05-30T19:33:39.327Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open(GLOVE_DIR, encoding=\"UTF-8\")\n",
    "print('Loading GloVe from:', GLOVE_DIR,'...', end='')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    embeddings_index[word] = np.asarray(values[1:], dtype='float32')\n",
    "f.close()\n",
    "print(\"Done.\\n Proceeding with Embedding Matrix...\", end=\"\")\n",
    "\n",
    "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print(\" Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.147517Z",
     "start_time": "2020-05-30T19:33:39.330Z"
    }
   },
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                           EMBEDDING_DIM,\n",
    "                           weights = [embedding_matrix],\n",
    "                           input_length = MAX_SEQUENCE_LENGTH,\n",
    "                           trainable=False,\n",
    "                           name = 'embeddings')\n",
    "embedded_sequences = embedding_layer(sequence_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.149511Z",
     "start_time": "2020-05-30T19:33:39.332Z"
    }
   },
   "outputs": [],
   "source": [
    "x = LSTM(60, return_sequences=True,name='lstm_layer')(embedded_sequences)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "preds = Dense(4, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.150510Z",
     "start_time": "2020-05-30T19:33:39.334Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.02)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer=opt,\n",
    "             weighted_metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.151507Z",
     "start_time": "2020-05-30T19:33:39.338Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.152504Z",
     "start_time": "2020-05-30T19:33:39.340Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Training progress:')\n",
    "history = model.fit(x_train, y_train, epochs = 10, batch_size=64, validation_data=(x_val, y_val), verbose=2, \n",
    "                    class_weight=class_weights)\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.153502Z",
     "start_time": "2020-05-30T19:33:39.343Z"
    }
   },
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history) \n",
    "\n",
    "hist_df.to_csv(\"data/output_csv/dimensions_hist_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.154499Z",
     "start_time": "2020-05-30T19:33:39.345Z"
    }
   },
   "outputs": [],
   "source": [
    "dimensions_hist_df = pd.read_csv(\"data/output_csv/dimensions_hist_df.csv\")\n",
    "dimensions_hist_df.drop([\"Unnamed: 0\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.156493Z",
     "start_time": "2020-05-30T19:33:39.347Z"
    }
   },
   "outputs": [],
   "source": [
    "dimensions_hist_df['val_f1'] = ((dimensions_hist_df[\"val_precision_1\"]*dimensions_hist_df[\"val_recall_1\"])/\n",
    "                                (dimensions_hist_df[\"val_precision_1\"]+dimensions_hist_df[\"val_recall_1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.157495Z",
     "start_time": "2020-05-30T19:33:39.350Z"
    }
   },
   "outputs": [],
   "source": [
    "dimensions_hist_df = dimensions_hist_df[['val_loss', 'loss', 'val_accuracy', 'accuracy', 'val_precision_1', 'precision_1',\n",
    "                  'val_recall_1', 'recall_1', 'val_f1']]\n",
    "dimensions_hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.159486Z",
     "start_time": "2020-05-30T19:33:39.352Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "plt.plot(dimensions_hist_df[['val_accuracy', 'val_precision_1', 'val_recall_1', 'val_f1']])\n",
    "plt.plot ( dimensions_hist_df[['accuracy', 'precision_1', 'recall_1']], '--' )\n",
    "\n",
    "plt.title('Training and Validation: Dimensions')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Metrics')\n",
    "plt.legend(['val_accuracy', 'val_precision_1', 'val_recall_1', 'val_f1', 'accuracy', 'precision_1', 'recall_1'])\n",
    "plt.savefig(\"images/output_images/dimensions_history.png\")\n",
    "\n",
    "sns.set_context(\"talk\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.125577Z",
     "start_time": "2020-05-30T19:33:39.287Z"
    }
   },
   "outputs": [],
   "source": [
    "mbti_df_clean = pd.read_pickle(\"data/output_pickles/mbti_clean_text.pkl\")\n",
    "result_umap_dimensions  = pd.read_csv(\"data/output_csv/result_umap_dimensions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.126587Z",
     "start_time": "2020-05-30T19:33:39.289Z"
    }
   },
   "outputs": [],
   "source": [
    "mbti_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.127571Z",
     "start_time": "2020-05-30T19:33:39.291Z"
    }
   },
   "outputs": [],
   "source": [
    "result_umap_dimensions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.129566Z",
     "start_time": "2020-05-30T19:33:39.294Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(result_umap_dimensions[\"i-e\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    i-e: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_dimensions[\"n-s\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    n-s: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_dimensions[\"t-f\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    t-f: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "neg, pos = np.bincount(result_umap_dimensions[\"j-p\"])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n    j-p: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.130563Z",
     "start_time": "2020-05-30T19:33:39.296Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "labels_dict = {0: 1999 , 1: 1997, 2: 4694, 3: 5241}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.131560Z",
     "start_time": "2020-05-30T19:33:39.299Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_class_weight(labels_dict):\n",
    "    total = 8675\n",
    "    keys = labels_dict.keys()\n",
    "    class_weight = dict()\n",
    "\n",
    "    for key in keys:\n",
    "        score = math.log(total/float(labels_dict[key]))\n",
    "        class_weight[key] = score if score > 1.0 else 1.0\n",
    "\n",
    "    return class_weight\n",
    "\n",
    "class_weights = create_class_weight(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.132569Z",
     "start_time": "2020-05-30T19:33:39.301Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = [\"i-e\", \"n-s\", \"t-f\", \"j-p\"]\n",
    "y = result_umap_dimensions[labels].values\n",
    "X = mbti_df_clean[\"posts_clean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.133556Z",
     "start_time": "2020-05-30T19:33:39.304Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "print ((X_train.shape),(y_train.shape),(X_test.shape),(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.134553Z",
     "start_time": "2020-05-30T19:33:39.307Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = list(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.135550Z",
     "start_time": "2020-05-30T19:33:39.309Z"
    }
   },
   "outputs": [],
   "source": [
    "texts = [line for line in X_train] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.136547Z",
     "start_time": "2020-05-30T19:33:39.311Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.138543Z",
     "start_time": "2020-05-30T19:33:39.314Z"
    }
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "print('Vocabulary size:', len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.140541Z",
     "start_time": "2020-05-30T19:33:39.316Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pad_sequences(sequences, padding = 'post', maxlen = MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.141551Z",
     "start_time": "2020-05-30T19:33:39.318Z"
    }
   },
   "outputs": [],
   "source": [
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = y_train[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.142531Z",
     "start_time": "2020-05-30T19:33:39.320Z"
    }
   },
   "outputs": [],
   "source": [
    "num_validation_samples = int(VALIDATION_SPLIT*data.shape[0])\n",
    "x_train = data[: -num_validation_samples]\n",
    "y_train = labels[: -num_validation_samples]\n",
    "x_val = data[-num_validation_samples: ]\n",
    "y_val = labels[-num_validation_samples: ]\n",
    "\n",
    "print ((x_train.shape),(y_train.shape),(x_val.shape),(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.143528Z",
     "start_time": "2020-05-30T19:33:39.323Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of entries in each category:')\n",
    "print('training: ', y_train.sum(axis=0))\n",
    "print('validation: ', y_val.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.145523Z",
     "start_time": "2020-05-30T19:33:39.325Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Tokenized sentences: \\n', data[10])\n",
    "print('One hot label: \\n', labels[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.146520Z",
     "start_time": "2020-05-30T19:33:39.327Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open(GLOVE_DIR, encoding=\"UTF-8\")\n",
    "print('Loading GloVe from:', GLOVE_DIR,'...', end='')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    embeddings_index[word] = np.asarray(values[1:], dtype='float32')\n",
    "f.close()\n",
    "print(\"Done.\\n Proceeding with Embedding Matrix...\", end=\"\")\n",
    "\n",
    "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print(\" Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.147517Z",
     "start_time": "2020-05-30T19:33:39.330Z"
    }
   },
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                           EMBEDDING_DIM,\n",
    "                           weights = [embedding_matrix],\n",
    "                           input_length = MAX_SEQUENCE_LENGTH,\n",
    "                           trainable=False,\n",
    "                           name = 'embeddings')\n",
    "embedded_sequences = embedding_layer(sequence_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.149511Z",
     "start_time": "2020-05-30T19:33:39.332Z"
    }
   },
   "outputs": [],
   "source": [
    "x = LSTM(60, return_sequences=True,name='lstm_layer')(embedded_sequences)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "preds = Dense(4, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.160483Z",
     "start_time": "2020-05-30T19:33:39.355Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.005)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer=opt,\n",
    "             weighted_metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.161480Z",
     "start_time": "2020-05-30T19:33:39.358Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.162477Z",
     "start_time": "2020-05-30T19:33:39.360Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Training progress:')\n",
    "history = model.fit(x_train, y_train, epochs = 10, batch_size=64, validation_data=(x_val, y_val), verbose=2, \n",
    "                    class_weight=class_weights)\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.163474Z",
     "start_time": "2020-05-30T19:33:39.362Z"
    }
   },
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history) \n",
    "\n",
    "hist_df.to_csv(\"data/output_csv/dimensions_hist_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.164471Z",
     "start_time": "2020-05-30T19:33:39.365Z"
    }
   },
   "outputs": [],
   "source": [
    "dimensions_hist_df = pd.read_csv(\"data/output_csv/dimensions_hist_df.csv\")\n",
    "dimensions_hist_df.drop([\"Unnamed: 0\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.165470Z",
     "start_time": "2020-05-30T19:33:39.368Z"
    }
   },
   "outputs": [],
   "source": [
    "dimensions_hist_df['val_f1'] = ((dimensions_hist_df[\"val_precision_1\"]*dimensions_hist_df[\"val_recall_1\"])/\n",
    "                                (dimensions_hist_df[\"val_precision_1\"]+dimensions_hist_df[\"val_recall_1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.167465Z",
     "start_time": "2020-05-30T19:33:39.371Z"
    }
   },
   "outputs": [],
   "source": [
    "dimensions_hist_df = dimensions_hist_df[['val_loss', 'loss', 'val_accuracy', 'accuracy', 'val_precision_1', 'precision_1',\n",
    "                  'val_recall_1', 'recall_1', 'val_f1']]\n",
    "dimensions_hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:37:45.168462Z",
     "start_time": "2020-05-30T19:33:39.375Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "plt.plot(dimensions_hist_df[['val_accuracy', 'val_precision_1', 'val_recall_1', 'val_f1']])\n",
    "plt.plot ( dimensions_hist_df[['accuracy', 'precision_1', 'recall_1']], '--' )\n",
    "\n",
    "plt.title('Training and Validation: Dimensions')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Metrics')\n",
    "plt.legend(['val_accuracy', 'val_precision_1', 'val_recall_1', 'val_f1', 'accuracy', 'precision_1', 'recall_1'])\n",
    "plt.savefig(\"images/output_images/dimensions_history.png\")\n",
    "\n",
    "sns.set_context(\"talk\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best F1 Scores for both models, the one using types and the one using dimensions, are pretty much the seme, being 0.24 and 0.23 respectively, but are still much lower than the scores obtained using ML models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Need to check how to add posts lengths and number of words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
